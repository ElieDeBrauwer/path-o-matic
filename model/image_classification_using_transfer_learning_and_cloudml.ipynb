{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying your own images using transfer learning and Google Cloud ML Engine\n",
    "---\n",
    "## Introduction\n",
    "This notebook can be used to classify a new dataset of images using *transfer learning* based on *Google Cloud Machine Learning Engine*.\n",
    "\n",
    "It is based on the following github repo: https://github.com/amygdala/tensorflow-workshop.git\n",
    "\n",
    "The notebook is intended to be executed from inside the *__tensorflow-workshop/workshop_sections/transfer_learning/cloudml/__* directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "project_name = \"pathomatic\"\n",
    "user_name = \"bardi\"\n",
    "model_version = \"v1\"\n",
    "train_on_cloud = True\n",
    "predict_on_cloud = True\n",
    "skip_preproc = True\n",
    "optimize_hyper_parameters = False\n",
    "model_type = \"multi_resolution\" # Supported: \"baseline\" or \"multi_resolution\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "from datetime import datetime\n",
    "\n",
    "# Helper function for printing out streaming subprocess output\n",
    "import subprocess\n",
    "import sys\n",
    "def exec_subprocess(cmd):\n",
    "  proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, shell=True)\n",
    "  while proc.poll() is None:\n",
    "    line = proc.stdout.readline()\n",
    "    sys.stdout.write(line)\n",
    "  # Might still be data on stdout at this point. Grab any remainder.\n",
    "  for line in proc.stdout.read().split('\\n'):\n",
    "    sys.stdout.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Retrieve the Project ID\n",
    "project_id_rd = !gcloud config list project --format \"value(core.project)\"\n",
    "project_id = project_id_rd.fields()[0][0]\n",
    "print (\"Project ID: %s\" % project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the Google Storage bucket\n",
    "bucket = \"gs://%s-%s-ml\" % (project_id, project_name)\n",
    "print (\"Bucket name: %s\" % bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a timestemp for the pre-processing JOB ID\n",
    "# Note that DataFlow doesn't like underscores\n",
    "timestamp_preproc = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "print(\"Time stamp: %s\" % timestamp_preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Execute the pre-processing\n",
    "if not skip_preproc:\n",
    "  exec_subprocess(\"chmod a+x ./%s_preproc.sh\" % project_name)\n",
    "  exec_subprocess(\"USER=%s DATE=%s ./%s_preproc.sh %s\" % (user_name, timestamp_preproc, project_name, bucket))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define pre-processing data output path\n",
    "if skip_preproc:\n",
    "  gcs_path_preproc = \"gs://asl_project/preproc\"\n",
    "else:\n",
    "  gcs_path_preproc = \"%s/%s/preproc/%s\" % (bucket, user_name, timestamp_preproc)\n",
    "print (\"Google Cloud Storage pre-processing path: %s\" % gcs_path_preproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: pathomatic_bardi_20170804_171019\n"
     ]
    }
   ],
   "source": [
    "# Define training Job ID\n",
    "timestamp_training = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "job_id=(\"%s_%s_%s\" % (project_name, user_name, timestamp_training)).replace('-', \"_\")\n",
    "print (\"Job ID: %s\" % job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define training path\n",
    "gcs_path_train = \"%s/%s/train/%s\" % (bucket, user_name, timestamp_training)\n",
    "print (\"Google Cloud Storage training path: %s\" % gcs_path_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optionally enable hyper parameter tuning:\n",
    "if optimize_hyper_parameters:\n",
    "  config_hp = \" --config hp_config.yaml\"\n",
    "else:\n",
    "  config_hp = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run the training on CLOUD\n",
    "# =========================\n",
    "#\n",
    "# This script will output summary and model checkpoint information under <gcs_path>/training\n",
    "#\n",
    "# If --package-path /my/code/path/trainer is specified and there is a setup.py file \n",
    "# at /my/code/path/setup.py then that file will be invoked with sdist and the generated tar files\n",
    "# will be uploaded to Cloud Storage. Otherwise a temporary setup.py file will be generated for the build.\n",
    "#\n",
    "# See https://cloud.google.com/sdk/gcloud/reference/ml-engine/jobs/submit/training\n",
    "#\n",
    "# The scale-tier story:\n",
    "# > Options are: BASIC, BASIC_GPU, STANDARD_1, PREMIUM_1 or CUSTOM\n",
    "# > By default there are 25 ML units available. A PREMIUM_1 scale-tier however requires 75 ML units.\n",
    "# > To speed-up training we've requested an upgrade to 100 ML units\n",
    "# > using the 'Cloud Machine Learning Engine Quota Request form' on https://cloud.google.com/ml-engine/quotas\n",
    "#\n",
    "# Currently unused flags:\n",
    "# --config=CONFIG\n",
    "# > Path to the job configuration file. The file should be a YAML document (JSON also accepted)\n",
    "# > containing a Job resource as defined in the API (all fields are optional)\n",
    "# > https://cloud.google.com/ml/reference/rest/v1/projects.jobs\n",
    "# > If an option is specified both in the configuration file and via command line arguments,\n",
    "# > the command line arguments override the configuration file.\n",
    "#\n",
    "# --job-dir=JOB_DIR\n",
    "# > A Google Cloud Storage path in which to store training outputs and other data needed for training.\n",
    "# > This path will be passed to your TensorFlow program as --job_dir command-line arg.\n",
    "# > The benefit of specifying this field is that Cloud ML Engine will validate the path for use in training.\n",
    "# > If packages must be uploaded and --staging-bucket is not provided, this path will be used instead.\n",
    "#\n",
    "# --packages=[PACKAGE,â€¦]\n",
    "# > Path to Python archives used for training. These can be local paths (absolute or relative),\n",
    "# > in which case they will be uploaded to the Cloud Storage bucket given by --staging-bucket,\n",
    "# > or Cloud Storage URLs (gs://bucket-name/path/to/package.tar.gz).\n",
    "#\n",
    "# --staging-bucket=STAGING_BUCKET\n",
    "# > Bucket in which to stage training archives.\n",
    "# > Required only if a file upload is necessary (that is, other flags include local paths)\n",
    "# > and no other flags implicitly specify an upload path.\n",
    "#\n",
    "# > --stream-logs\n",
    "# > Block until job completion and stream the logs while the job runs.\n",
    "# > Note that even if command execution is halted, the job will still run until cancelled with\n",
    "if train_on_cloud:\n",
    "  exec_subprocess(\"gcloud ml-engine jobs submit training %s\" % job_id + \\\n",
    "    \" --module-name trainer.task\" + \\\n",
    "    \" --package-path trainer\" + \\\n",
    "    \" --staging-bucket %s\" % bucket + \\\n",
    "    \" --region us-central1\" + \\\n",
    "    \" --runtime-version 1.2\" + \\\n",
    "    \" --scale-tier PREMIUM_1\" + \\\n",
    "    config_hp + \\\n",
    "    \" --\" + \\\n",
    "    \" --output_path %s\" % (gcs_path_train + \"/training\") + \\\n",
    "    \" --eval_data_paths %s\" % (gcs_path_preproc + \"/eval*\") + \\\n",
    "    \" --train_data_paths %s\" % (gcs_path_preproc + \"/train*\") + \\\n",
    "    \" --eval_set_size 474\" + \\\n",
    "    \" --eval_batch_size 75\" + \\\n",
    "    \" --classifier_label_count 2\" + \\\n",
    "    \" --max_steps 10000\" + \\\n",
    "    \" --model_type %s\" % model_type)\n",
    "\n",
    "# Run the training locally\n",
    "# ========================\n",
    "#\n",
    "# Note that max_steps is configured much lower.\n",
    "# This is because local training is typically used for initial checks.\n",
    "# Once local training is working, we can switch to cloud training\n",
    "if not train_on_cloud:\n",
    "  exec_subprocess(\"gcloud ml-engine local train\" + \\\n",
    "    \" --module-name trainer.task\" + \\\n",
    "    \" --package-path trainer\" + \\\n",
    "    \" --\" + \\\n",
    "    \" --output_path %s\" % (gcs_path_train + \"/training\") + \\\n",
    "    \" --eval_data_paths %s\" % (gcs_path_preproc + \"/eval*\") + \\\n",
    "    \" --train_data_paths %s\" % (gcs_path_preproc + \"/train*\") + \\\n",
    "    \" --eval_set_size 474\" + \\\n",
    "    \" --eval_batch_size 25\" + \\\n",
    "    \" --classifier_label_count 2\" + \\\n",
    "    \" --max_steps 10\" + \\\n",
    "    \" --model_type %s\" % model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Monitor the training\n",
    "exec_subprocess(\"gcloud ml-engine jobs stream-logs %s\" % (job_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# See the results in TensorBoard\n",
    "from google.datalab.ml import TensorBoard\n",
    "pid = TensorBoard.start(\"%s/training\" % gcs_path_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# See the running TensorBoard's\n",
    "TensorBoard.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Execute this cell to stop the previously started TensorBoard process\n",
    "TensorBoard.stop(pid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2017-08-03T23:26:32Z'\n",
      "endTime: '2017-08-04T02:43:16Z'\n",
      "jobId: pathomatic_bardi_20170803_232452\n",
      "startTime: '2017-08-03T23:26:35Z'\n",
      "state: SUCCEEDED\n",
      "trainingInput:\n",
      "  args:\n",
      "  - --output_path\n",
      "  - gs://asl_project/bardi/train/20170803-232452/training\n",
      "  - --eval_data_paths\n",
      "  - gs://asl_project/preproc/eval*\n",
      "  - --train_data_paths\n",
      "  - gs://asl_project/preproc/train*\n",
      "  - --eval_set_size\n",
      "  - '474'\n",
      "  - --eval_batch_size\n",
      "  - '25'\n",
      "  - --classifier_label_count\n",
      "  - '2'\n",
      "  - --max_steps\n",
      "  - '100000'\n",
      "  - --model_type=baseline\n",
      "  hyperparameters:\n",
      "    goal: MAXIMIZE\n",
      "    maxParallelTrials: 1\n",
      "    maxTrials: 10\n",
      "    params:\n",
      "    - maxValue: 200.0\n",
      "      minValue: 50.0\n",
      "      parameterName: batch_size\n",
      "      scaleType: UNIT_LINEAR_SCALE\n",
      "      type: INTEGER\n",
      "  packageUris:\n",
      "  - gs://asl_project/pathomatic_bardi_20170803_232452/71c8cb0ea5796d0fb889631b2fbc8321ae69304ef5e712dcf2a106009e388f1f/trainer-0.1.tar.gz\n",
      "  pythonModule: trainer.task\n",
      "  region: us-central1\n",
      "  runtimeVersion: '1.2'\n",
      "  scaleTier: PREMIUM_1\n",
      "trainingOutput:\n",
      "  completedTrialCount: '10'\n",
      "  consumedMLUnits: 222.15\n",
      "  isHyperparameterTuningJob: true\n",
      "  trials:\n",
      "  - finalMetric:\n",
      "      objectiveValue: 0.928889\n",
      "      trainingStep: '100025'\n",
      "    hyperparameters:\n",
      "      batch_size: '50'\n",
      "    trialId: '3'\n",
      "  - finalMetric:\n",
      "      objectiveValue: 0.922222\n",
      "      trainingStep: '100019'\n",
      "    hyperparameters:\n",
      "      batch_size: '50'\n",
      "    trialId: '6'\n",
      "  - finalMetric:\n",
      "      objectiveValue: 0.917778\n",
      "      trainingStep: '100027'\n",
      "    hyperparameters:\n",
      "      batch_size: '50'\n",
      "    trialId: '8'\n",
      "  - finalMetric:\n",
      "      objectiveValue: 0.915556\n",
      "      trainingStep: '100038'\n",
      "    hyperparameters:\n",
      "      batch_size: '50'\n",
      "    trialId: '7'\n",
      "  - finalMetric:\n",
      "      objectiveValue: 0.913333\n",
      "      trainingStep: '100038'\n",
      "    hyperparameters:\n",
      "      batch_size: '50'\n",
      "    trialId: '5'\n",
      "  - finalMetric:\n",
      "      objectiveValue: 0.911111\n",
      "      trainingStep: '100038'\n",
      "    hyperparameters:\n",
      "      batch_size: '50'\n",
      "    trialId: '10'\n",
      "  - finalMetric:\n",
      "      objectiveValue: 0.908889\n",
      "      trainingStep: '100038'\n",
      "    hyperparameters:\n",
      "      batch_size: '50'\n",
      "    trialId: '9'\n",
      "  - finalMetric:\n",
      "      objectiveValue: 0.902222\n",
      "      trainingStep: '100020'\n",
      "    hyperparameters:\n",
      "      batch_size: '50'\n",
      "    trialId: '4'\n",
      "  - finalMetric:\n",
      "      objectiveValue: 0.9\n",
      "      trainingStep: '100039'\n",
      "    hyperparameters:\n",
      "      batch_size: '122'\n",
      "    trialId: '1'\n",
      "  - finalMetric:\n",
      "      objectiveValue: 0.897778\n",
      "      trainingStep: '100033'\n",
      "    hyperparameters:\n",
      "      batch_size: '200'\n",
      "    trialId: '2'\n",
      "\n",
      "View job in the Cloud Console at:\n",
      "https://console.cloud.google.com/ml/jobs/pathomatic_bardi_20170803_232452?project=qwiklabs-gcp-b99b43902e05a4b7\n",
      "\n",
      "View logs at:\n",
      "https://console.cloud.google.com/logs?resource=ml.googleapis.com%2Fjob_id%2Fpathomatic_bardi_20170803_232452&project=qwiklabs-gcp-b99b43902e05a4b7\n"
     ]
    }
   ],
   "source": [
    "# Deploy the model\n",
    "# This will give an error if the model already exists, but this is expected and OK.\n",
    "model_name = \"%s_%s\" % (project_name, model_type)\n",
    "exec_subprocess(\"chmod a+x ./model.sh\")\n",
    "#check the relevant task id\n",
    "if optimize_hyper_parameters:\n",
    "    exec_subprocess(\"gcloud ml-engine jobs describe %s\" % (job_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://asl_project/bardi/train/20170803-232452/training/3\n",
      "\n",
      "Using GCS_PATH:  gs://asl_project/bardi/train/20170803-232452/training/3\n",
      "Using VERSION_NAME:  v1\n",
      "Using MODEL NAME:  test\n",
      "\n",
      "# Tell CloudML about a new type of model coming.  Think of a \"model\" here as\n",
      "# a namespace for deployed Tensorflow graphs.  This will give an error\n",
      "# if the model already exists.\n",
      "gcloud ml-engine models create \"$MODEL_NAME\" --regions us-central1\n",
      "\n",
      "set -e\n",
      "\n",
      "# Each unique Tensorflow graph--with all the information it needs to execute--\n",
      "# corresponds to a \"version\".  Creating a version actually deploys our\n",
      "# Tensorflow graph to a Cloud instance, and gets it ready to serve (predict).\n",
      "# This will give an error if the version name already exists.\n",
      "gcloud ml-engine versions create \"$VERSION_NAME\" \\\n",
      "  --model \"$MODEL_NAME\" \\\n",
      "  --origin \"${GCS_PATH}/model\"\n",
      "Creating version (this might take a few minutes)......\n",
      ".......................................................................................................done.\n",
      "\n",
      "# Models do not need a default version, but it's a great way to move\n",
      "# your production\n",
      "# service from one version to another with a single gcloud command.\n",
      "gcloud ml-engine versions set-default \"$VERSION_NAME\" --model \"$MODEL_NAME\"\n",
      "createTime: '2017-08-04T17:16:14Z'\n",
      "deploymentUri: gs://asl_project/bardi/train/20170803-232452/training/3/model\n",
      "isDefault: true\n",
      "name: projects/qwiklabs-gcp-b99b43902e05a4b7/models/test/versions/v1\n",
      "state: READY\n",
      "\n",
      "# Now, generate a request json file with test image(s). If you trained a model\n",
      "# with the 'flower' images, edit the image list appropriately.\n",
      "python images_to_json.py -o request.json prediction_images/knife.jpg prediction_images/puppy2.jpg prediction_images/hedgehog.jpg\n",
      "All inputs must be .jpeg or .jpg or .png"
     ]
    }
   ],
   "source": [
    "if optimize_hyper_parameters:\n",
    "  task_id = 3 #change to the task id with the best performance\n",
    "  gcs_path_deploy = \"%s/training/%s\" %(gcs_path_train,task_id)\n",
    "else:\n",
    "  gcs_path_deploy = gcs_path_train\n",
    "print( gcs_path_deploy)\n",
    "exec_subprocess(\"./model.sh %s %s %s\" % (gcs_path_deploy, model_version, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get a list of deployed models\n",
    "!gcloud ml-engine models list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare prediction request.json\n",
    "exec_subprocess(\"python images_to_json.py -o request.json ./prediction_images/%s.png\" % model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run predictions on a number of images\n",
    "if predict_on_cloud:\n",
    "  exec_subprocess(\"gcloud ml-engine predict --model %s --json-instances request.json \" % (model_name))\n",
    "else:\n",
    "  exec_subprocess(\"gcloud ml-engine local predict --model-dir %s/training/model --json-instances request.json \" % (gcs_path_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "hiddenCell": false
   },
   "outputs": [],
   "source": [
    "# If needed, run the following to update gcloud\n",
    "#!yes | gcloud components update"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
